{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tflearn\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import wordnet\n",
    "import answer_questions\n",
    "import numpy as np\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_label.pickle','rb') as f:\n",
    "    training = pickle.load(f)\n",
    "with open('word_token.pickle','rb') as f:\n",
    "    words = pickle.load(f)\n",
    "word_set = set(words)\n",
    "    \n",
    "data = list(training[:, 0])\n",
    "label = list(training[:, 1])\n",
    "\n",
    "# reset underlying graph data\n",
    "tf.reset_default_graph()\n",
    "# Build neural network\n",
    "net = tflearn.input_data(shape=[None, len(data[0])])\n",
    "net = tflearn.fully_connected(net, 64, activation='relu')\n",
    "net = tflearn.fully_connected(net, 64, activation='relu')\n",
    "net = tflearn.fully_connected(net, len(label[0]), activation='softmax')\n",
    "net = tflearn.regression(net)\n",
    " \n",
    "# Define model and setup tensorboard\n",
    "model = tflearn.DNN(net, tensorboard_dir='tflearn_logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /home/yitao/Documents/clerkie_tenserflow/tf_nn.model\n"
     ]
    }
   ],
   "source": [
    "model.load('tf_nn.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf_record(sentence):\n",
    "    global words\n",
    "    # tokenize the pattern\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer.stem(word.lower()) for word in sentence_words]\n",
    "    # bag of words\n",
    "    bow = [0]*len(words)\n",
    "    for s in sentence_words:\n",
    "        for i, w in enumerate(words):\n",
    "            if w == s:\n",
    "                bow[i] = 1\n",
    "\n",
    "    return(np.array(bow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_question_unlabel(user_input):\n",
    "    f = open(\"unlabeled.csv\", \"a\")\n",
    "    f.write(\"{}\\n\".format(user_input))\n",
    "    f.close()\n",
    "    print(\"sorry, I'm still learning :p, but I've saved your question for future learning\")\n",
    "def add_question_pseudo_label(class_name, user_input):\n",
    "    f = open(\"pseudo_label.csv\", \"a\")\n",
    "    f.write(\"{},{}\\n\".format(class_name, user_input))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capture entities in questions belong to category 1.\n",
    "# extract bank names, checking/saving, account number\n",
    "def cap_entities(user_input):\n",
    "    token = nltk.word_tokenize(user_input)\n",
    "    tagged = nltk.pos_tag(token)\n",
    "    bank_set = set(['boa','bankofamerica','chase','citi'])\n",
    "    bank_id_type = ['','','']\n",
    "    potential_bank_name = ''\n",
    "    for i,x in enumerate(tagged):\n",
    "        if x[0] in bank_set:\n",
    "            bank_id_type[0] = x[0]\n",
    "        elif x[1] == 'CD':\n",
    "            bank_id_type[1] = x[0]\n",
    "        elif x[0] == 'checking' or x[0] == 'saving' or x[0] == 'credit':\n",
    "            bank_id_type[2] = x[0]\n",
    "\n",
    "    return bank_id_type\n",
    "\n",
    "\n",
    "# capture entities in questions belong to category 3. \n",
    "# determine if the user is asking about buying houses\n",
    "# return price only if user specified a price\n",
    "# and the question is about buying house\n",
    "def house_keyword(user_input):\n",
    "    token = nltk.word_tokenize(user_input)\n",
    "    tagged = nltk.pos_tag(token)\n",
    "    price = '0'\n",
    "    flag = False\n",
    "    similarity_threshold = 0.8\n",
    "    house_set = ['house',\n",
    "                 'condo',\n",
    "                 'pad',\n",
    "                 'crib',\n",
    "                 'apartment',\n",
    "                 'residence',\n",
    "                 'mansion'\n",
    "                ]\n",
    "    for x in tagged:\n",
    "        if x[1] == 'CD':\n",
    "            price = x[0]\n",
    "        if 'NN' in x[1]:\n",
    "            try:\n",
    "                w1 = wordnet.synset('{}.n.01'.format(x[0]))\n",
    "            except:\n",
    "                continue\n",
    "            for word in house_set:\n",
    "                w2 = wordnet.synset('{}.n.01'.format(word))\n",
    "                if w1.wup_similarity(w2) > similarity_threshold:\n",
    "                    flag = True\n",
    "                    break\n",
    "    return price if flag else '-1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_up_sentence(sentence):\n",
    "    # tokenize the pattern\n",
    "    sentence_words = nltk.word_tokenize(sentence)\n",
    "    # stem each word\n",
    "    sentence_words = [stemmer.stem(word) for word in sentence_words]\n",
    "    return sentence_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(text):\n",
    "    \n",
    "    classes = ['1.check balance','2.check budget','3.house affordability',\n",
    "                '4.loan', '5.mortgage FAQ', '6.Check spending']\n",
    "    ERROR_THRESHOLD = 0.65\n",
    "    result = model.predict([get_tf_record(text)])\n",
    "    prediction = np.argmax(result)\n",
    "    prob = result[0][prediction]\n",
    "    \n",
    "    if prob < ERROR_THRESHOLD:\n",
    "        prediction = 6\n",
    "        print('class:','unidentified','|| prob:','N/A')\n",
    "    else:\n",
    "        print('class:',classes[prediction],'|| prob:',prob)\n",
    "    return prediction, prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main function\n",
    "def ask_clerkie():\n",
    "    print(\"\\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "    user_input = input(\"what's your financial question? (type 'quit' to exit.) \\n\\n\").lower()\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    if 'hello' in user_input:\n",
    "        print('Hi :D, do you have a financial question?')\n",
    "        return True\n",
    "    #quitting outer loop\n",
    "    elif user_input == 'quit':\n",
    "        print('Thanks for using clerkie :D')\n",
    "        print(\"\\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\")\n",
    "        return False\n",
    "    \n",
    "    #if user input nothing\n",
    "    elif len(user_input) == 0:\n",
    "        print('Ask Me a question :D')\n",
    "        return True\n",
    "    user_token = clean_up_sentence(user_input)\n",
    "    related_token = 0\n",
    "    \n",
    "    \n",
    "    #is user question relatable?\n",
    "    related_threshold = 0.2\n",
    "    #check how many tokens are related to financial questions\n",
    "    #also calculate the related percentage\n",
    "    for token in user_token:\n",
    "        if token in word_set:\n",
    "            related_token += 1\n",
    "    \n",
    "    #related question, and question length more than 2 words\n",
    "    if related_token/len(user_token) >= related_threshold and len(user_token) >= 2:\n",
    "        question_class, prob = classify(user_input)\n",
    "        \n",
    "        #this means the question is not recognized by Clerkie\n",
    "        #ask user's help to label the question\n",
    "        #and save to file for future learning\n",
    "        if question_class == 6:\n",
    "            add_question_unlabel(user_input)\n",
    "                \n",
    "        \n",
    "        else:\n",
    "            if prob >=0.85:\n",
    "                add_question_pseudo_label(question_class, user_input)\n",
    "            \n",
    "            #question that classified as category 1\n",
    "            if question_class == 0:\n",
    "                bank_id_type = cap_entities(user_input)\n",
    "                alternative_name = {'bankofamerica':'boa'}\n",
    "                if bank_id_type[0] in alternative_name:\n",
    "                    bank_id_type[0] = alternative_name[bank_id_type[0]]\n",
    "                answer_questions.get_balance(bank_id_type)\n",
    "\n",
    "            #question that classified as category 2\n",
    "            elif question_class == 1:\n",
    "                answer_questions.get_budget()\n",
    "\n",
    "            #question that classified as category 3\n",
    "            elif question_class == 2:\n",
    "                price = house_keyword(user_input)\n",
    "\n",
    "                #question about buying things other than house\n",
    "                if price == '-1':\n",
    "                    print(\"sorry, I can only help with house affordability :p\")\n",
    "\n",
    "                #user didn't specify a price in the question\n",
    "                elif price == '0':\n",
    "                    print(\"sorry, please provide house price so I can help :p\")\n",
    "                else:\n",
    "                    answer_questions.is_affordable(price)\n",
    "            elif question_class == 3:\n",
    "                answer_questions.loan_question()\n",
    "\n",
    "\n",
    "            elif question_class == 4:\n",
    "                answer_questions.mortgage_FAQ()\n",
    "\n",
    "\n",
    "            elif question_class == 5:\n",
    "                answer_questions.spending()\n",
    "    else:\n",
    "        print(\"Please ask financial related question (more than 2 words) :p\")\n",
    "    return True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n",
      "what's your financial question? (type 'quit' to exit.) \n",
      "\n",
      "quit\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "Thanks for using clerkie :D\n",
      "\n",
      "XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "while flag:\n",
    "    flag = ask_clerkie()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
